{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Mirantis Secure Registry 4","text":""},{"location":"#overview","title":"Overview","text":"<p>Mirantis Secure Registry 4 (MSR 4) is an enterprise-grade container registry that seamlessly integrates with standard Kubernetes distributions to secure cloud-native development. Built on Harbor, the CNCF-graduated open-source container registry, MSR 4 is the cornerstone of a secure software supply chain.</p>"},{"location":"#key-features","title":"Key Features","text":"<ol> <li> <p>Flexible Deployment    Deploy alongside your applications on Kubernetes (v1.10+) using Docker Compose or Helm charts.</p> </li> <li> <p>Enhanced Security    Use policies and role-based access control (RBAC) to ensure container images are vulnerability-free.</p> </li> <li> <p>DevOps Collaboration    Push and share multiservice applications within your team while maintaining clear boundaries.</p> </li> <li> <p>Faster Image Distribution    Leverage peer-to-peer (P2P) preheating for accelerated image delivery.</p> </li> <li> <p>Policy-Based Automation    Promote images through testing to production with automated compliance checks, ensuring security standards are met.</p> </li> <li> <p>Pipeline Integration    Connect MSR 4 to your CI/CD pipeline with webhooks for automated, secure application delivery.</p> </li> </ol> <p>Mirantis Secure Registry 4 simplifies managing, securing, and distributing container images, helping organizations streamline their software supply chains.</p>"},{"location":"ha/","title":"MSR4 Installation with High Availability","text":""},{"location":"ha/#introduction","title":"Introduction","text":"<p>This document provides a comprehensive guide for installing <code>MSR4</code> in a lab environment with High Availability (HA). Future updates may include additional ingress options and advanced configuration settings.</p>"},{"location":"ha/#prerequisites","title":"Prerequisites","text":"<p>Before proceeding with the installation, the following prerequisites must be met:</p>"},{"location":"ha/#a-kubernets-cluster","title":"A Kubernets Cluster","text":"<p>An existing <code>Kubernetes</code> cluster with at least two Linux worker nodes is required. For this guide, TerraTrain was used to create the cluster.</p>"},{"location":"ha/#helm-installation","title":"Helm Installation","text":"<p>Helm must be installed and properly configured. If <code>TerraTrain</code> is being used, it should be noted that the version of Helm included in the container is outdated. It is recommended to upgrade Helm by running the following script:</p> <pre><code>curl -fsSL https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash\n</code></pre> <p>After upgrading, Helm commands should reference the full path to the updated Helm binary.</p>"},{"location":"ha/#client-bundle-setup","title":"Client Bundle Setup","text":"<p>The client bundle must be configured to execute Helm commands successfully. Instructions for setting up the client bundle can be found in the official documentation.</p> <p>:memo: The initial steps in this guide align closely with the non-HA installation documentation for MSR4, with additional instructions for enabling High Availability.</p>"},{"location":"ha/#step-1-add-the-msr-helm-repository","title":"Step 1: Add the MSR Helm Repository","text":"<pre><code>helm repo add harbor https://registry.mirantis.com/charts/harbor/helm\n</code></pre>"},{"location":"ha/#step-2-get-the-valuesyaml-file","title":"Step 2: Get the values.yaml file","text":"<pre><code>helm show values harbor/harbor &gt; values.yaml\n</code></pre>"},{"location":"ha/#step-3-create-the-k8s-secret-with-the-keys","title":"Step 3: Create the K8s Secret with the Keys","text":"<p>Create a folder called \"certs\"</p> <pre><code>mkdir certs\n</code></pre> <p>Create a text file called \"harbor.conf\" in the certs directory and fill it out with the following:</p> <pre><code>[req]\ndistinguished_name = req_distinguished_name\nx509_extensions = v3_req\nprompt = no\n\n[req_distinguished_name]\nC = US\nST = State\nL = City\nO = Organization\nOU = Organizational Unit\nCN = msr\n\n[v3_req]\nkeyUsage = keyEncipherment, dataEncipherment\nextendedKeyUsage = serverAuth\nsubjectAltName = @alt_names\n\n[alt_names]\nIP.1 = &lt;ip-address-of-workernode&gt;  # Replace with your actual IP address\n</code></pre> <p>Generate the crt and the key using the harbor.conf file you just created</p> <pre><code>openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout tls.key -out tls.crt -config harbor.conf\n</code></pre> <p>Create the k8s secret (run from outside of the certs folder):</p> <pre><code>kubectl create secret tls &lt;name of your secret&gt; \\\n--cert=certs/tls.crt \\\n--key=certs/tls.key\n</code></pre>"},{"location":"ha/#step-4-set-up-nfs-and-storageclass","title":"Step 4: Set up NFS and storageclass","text":"<p>Set Data Persistence method to true in the values.yaml file:</p> <pre><code>persistence:\nenabled: true\n</code></pre> <p>Set up the NFS folder on the NFS Server(note this assumes that NFS server is already installed) :</p> <pre><code>sudo mkdir -p &lt;directory you want to use&gt;\nsudo chown nobody:nogroup &lt;directory you want to use&gt;\nsudo chmod 777 &lt;directory you want to use&gt;\n</code></pre> <p>Add directory to the file /etc/exports on the NFS Server  with the following line:</p> <pre><code>&lt;/directory/you/want/touse&gt; &lt;node-ip&gt;(rw,sync,no_subtree_check,no_root_squash)\n</code></pre> <p>Exit the NFS Server and install NFS tools on your manager nodes: On Ubuntu:</p> <pre><code>sudo apt-get update\nsudo apt-get install nfs-common\n</code></pre> <p>On Redhat, Centos,  or Rocky:</p> <pre><code>sudo yum install nfs-utils\n</code></pre> <p>Run the following helm commands against your cluster:</p> <pre><code>helm repo add nfs-provisioner https://kubernetes-sigs.github.io/nfs-subdir-external-provisioner/\nhelm repo update\n</code></pre> <p>Make sure you add your nfs server ip in the appropriate spot in this command:</p> <pre><code>helm install nfs-client-provisioner nfs-provisioner/nfs-subdir-external-provisioner \\\n--set nfs.server=&lt;nfs-server-ip&gt; \\\n--set nfs.path=&lt;/directory/you/want/touse&gt; \\\n--set storageClass.name=nfs-storage \\\n--set storageClass.defaultClass=true\n</code></pre> <p>You should see a pod start up and if you run:</p> <pre><code>kubectl get storageclass\n</code></pre> <p>You should see the storageclass you created. Once the NFS pod is healthy you can move onto the next step.</p>"},{"location":"ha/#step-5-set-up-ha-redis","title":"Step 5: Set up HA Redis","text":"<p>Add the bitnami repo</p> <pre><code>helm repo add bitnami https://charts.bitnami.com/bitnami\n</code></pre> <p>Create a file called redis-values.yaml and populate with the following:</p> <pre><code>replica:\nreplicaCount: 3\npersistence:\nenabled: true\nsize: 8Gi\nresources:\nrequests:\nmemory: 256Mi\ncpu: 100m\nlimits:\nmemory: 512Mi\ncpu: 200m\n</code></pre> <p>Install redis via helm:</p> <pre><code>helm install redis bitnami/redis -f redis-values.yaml\n</code></pre> <p>Get and save the redis password (save it as environmental variable, that way you can recall it if you lose it):</p> <pre><code>export REDIS_PASSWORD=$(kubectl get secret --namespace default redis -o jsonpath=\"{.data.redis-password}\" | base64 -d)\necho $REDIS_PASSWORD\n</code></pre> <p>Get the service name and ip</p> <pre><code>kubectl get service\nredis-master                                   ClusterIP   10.96.84.98     &lt;none&gt;        6379/TCP\n</code></pre> <p>Modify the values.yaml file to set redis to external:</p> <pre><code>redis:\n# if external Redis is used, set \"type\" to \"external\"\n# and fill the connection information in \"external\" section\ntype: external\n</code></pre> <p>Modify the values.yaml file and add the details under redis external:</p> <pre><code>external:\n# support redis, redis+sentinel\n# addr for redis: &lt;host_redis&gt;:&lt;port_redis&gt;\n# addr for redis+sentinel: &lt;host_sentinel1&gt;:&lt;port_sentinel1&gt;,&lt;host_sentinel2&gt;:&lt;port_sentinel2&gt;,&lt;host_sentinel3&gt;:&lt;port_sentinel3&gt;\naddr: \"&lt;servicename:port&gt;\"\n# The name of the set of Redis instances to monitor, it must be set to support redis+sentinel\nsentinelMasterSet: \"\"\n# The \"coreDatabaseIndex\" must be \"0\" as the library Harbor\n# used doesn't support configuring it\n# harborDatabaseIndex defaults to \"0\", but it can be configured to \"6\", this config is optional\n# cacheLayerDatabaseIndex defaults to \"0\", but it can be configured to \"7\", this config is optional\ncoreDatabaseIndex: \"0\"\njobserviceDatabaseIndex: \"1\"\nregistryDatabaseIndex: \"2\"\ntrivyAdapterIndex: \"5\"\n# harborDatabaseIndex: \"6\"\n# cacheLayerDatabaseIndex: \"7\"\n# username field can be an empty string, and it will be authenticated against the default user\nusername: \"\"\npassword: \"&lt;password&gt;\"\n</code></pre>"},{"location":"ha/#step-6-set-up-postgresql","title":"Step 6: Set up Postgresql","text":"<p>Create and populate postgresql-values.yaml file</p> <pre><code>primary:\npersistence:\nenabled: true\nsize: 10Gi\nresources:\nlimits:\ncpu: 500m\nmemory: 512Mi\nrequests:\ncpu: 100m\nmemory: 256Mi\nreplica:\nreplicaCount: 3\nreplication:\nenabled: true\nsynchronousCommit: \"on\"\nnumSynchronousReplicas: 1\n</code></pre> <p>Install Postgresql via helm</p> <pre><code>helm install postgresql bitnami/postgresql-ha -f postgresql-values.yaml\n</code></pre> <p>Get Postgresql password</p> <pre><code>export POSTGRES_PASSWORD=$(kubectl get secret --namespace default postgresql-postgresql-ha-postgresql -o jsonpath=\"{.data.password}\" | base64 -d)\necho $POSTGRES_PASSWORD\n</code></pre> <p>Login to postgresql</p> <pre><code>kubectl run postgresql-postgresql-ha-client --rm --tty -i --restart='Never' --namespace default --image docker.io/bitnami/postgresql-repmgr:16.4.0-debian-12-r12 --env=\"PGPASSWORD=$POSTGRES_PASSWORD\"  \\\n--command -- psql -h postgresql-postgresql-ha-pgpool -p 5432 -U postgres -d postgres\n</code></pre> <p>Create Databases</p> <pre><code>CREATE DATABASE harbor_core;\nCREATE DATABASE clair;\nCREATE DATABASE notary_signer;\nCREATE DATABASE notary_server;\n</code></pre> <p>Find \"pool\" service and port</p> <pre><code>kubectl get service\npostgresql-postgresql-ha-pgpool                ClusterIP   10.96.40.233    &lt;none&gt;        5432/TCP\n</code></pre> <p>Set postgresql to be external in MSR4 values.yaml</p> <pre><code>database:\n# if external database is used, set \"type\" to \"external\"\n# and fill the connection information in \"external\" section\ntype: external\n</code></pre> <p>Fill out the portion under database external</p> <pre><code>external:\nhost: \"&lt;poolservicename&gt;\"\nport: \"&lt;port&gt;\"\nusername: \"postgres\"\npassword: \"&lt;password&gt;\"\ncoreDatabase: \"harbor_core\"\n</code></pre>"},{"location":"ha/#step-7-set-up-the-method-of-ingress-by-modifying-the-valuesyaml-file","title":"Step 7: Set up the Method of ingress by modifying the values.yaml file","text":"<p>Set the expose type:</p> <pre><code>expose:\n# Set how to expose the service. Set the type as \"ingress\", \"clusterIP\", \"nodePort\" or \"loadBalancer\"\n# and fill the information in the corresponding section\ntype: nodePort\n</code></pre> <p>Set the certsource to TLS and the Secret name to what you want</p> <pre><code>certSource: secret\nsecret:\n# The name of secret which contains keys named:\n# \"tls.crt\" - the certificate\n# \"tls.key\" - the private key\nsecretName: \"&lt;name of your secret&gt;\"\n</code></pre> <p>set the nodePort ports to allow nodePort ingress</p> <pre><code>nodePort:\n# The name of NodePort service\nname: harbor\nports:\nhttp:\n# The service port Harbor listens on when serving HTTP\nport: 80\n# The node port Harbor listens on when serving HTTP\nnodePort: 32769\nhttps:\n# The service port Harbor listens on when serving HTTPS\nport: 443\n# The node port Harbor listens on when serving HTTPS\nnodePort: 32770\n</code></pre> <p>Use a worker node ip address (the same one that you used in generating the cert):</p> <pre><code>externalURL: &lt;a worker node external IP:httpsnodePort&gt;\n</code></pre>"},{"location":"ha/#step-8-modify-the-yaml-for-replication","title":"Step 8: Modify the Yaml for replication","text":"<p>Set the replica number to at least 2 under portal, registry, core, trivy and jobservice in the values.yaml file</p>"},{"location":"ha/#step-9-install-via-helm","title":"Step 9: Install via Helm","text":"<pre><code>helm install my-release harbor/harbor -f &lt;pathto/values.yaml&gt;\n</code></pre>"},{"location":"ha/#step-10-allow-docker-environment-to-trust-self-signed-cert","title":"Step 10: Allow docker environment to trust Self Signed Cert","text":"<p>Allow Docker to trust the self-signed certificate:</p> <p>Create the directory:</p> <pre><code>mkdir -p /etc/docker/certs.d/&lt;worker-node-ip&gt;:32770\n</code></pre> <p>Move the certificate:</p> <pre><code>mv tls.crt /etc/docker/certs.d/&lt;worker-node-ip&gt;:32770/ca.crt\n</code></pre>"},{"location":"ha/#step-10-access-the-harbor-ui","title":"Step 10: Access the Harbor UI","text":"<p>Acccess the UI by pointing your browser to:</p> <pre><code>https://&lt;worker-node-ip&gt;:32770\n</code></pre> <p>Default login:</p> <p>Username: admin</p> <p>Password: Harbor12345</p>"},{"location":"intro/","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"intro/#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"intro/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"}]}